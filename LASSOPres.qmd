---
title: "LASSO, Ridge Regression, and Elastic Net Regularization"
format: 
  revealjs:
    theme: moon
    self-contained: false
    slide-number: false
    width: 1600
    height: 900
    df-print: paged
---

## Introduction / Linear Regression Overview

*Regression* is the predicting or learning of numerical features in statistics and machine learning which allows for data driven decisions over guesswork.

*Simple linear regression* is the relationship between one dependent variable and one independent variable to create a linear model that can be used to predict future outcomes.

*Multilinear regression* is more complex with the addition of more independent variables.

An issue can arise as the number of independent variables becomes too high resulting in less predictability which can be solved with *regularization*.

## What Is Regularization?

The process managing the independent variables in a way that maintains predictability.

Regression models that contain too many independent variables can have an issue with the linear model not fitting or predicting well.

[**Overfitting**]{.underline} the model is too close to the data provided which can cause a problem with different data sets and predicting future values

[**Underfitting**]{.underline} the model is not close enough to the current data to determine accurate predictions

To regularize models, we must manage the number and impact of independent variables. We can reduce the coefficients of the variables which decreases the impact of less important variables or eliminate the less impactful variables all together.

## Regularized Regression Methods

Three regularized regression methods are

Ridge, Elastic Net, and LASSO.

## Ridge Regression

-   Reduces the impact of the variables that are not as important in the prediction of the model by reducing the value of the coefficients to near zero

-   Can manage data sets in which the number of independent variables is greater than the number of observations in the data set. ( $p>n$)

-   Does not preform variable selection as all independent variables remain the model

-   Ridge regression uses a variable $\lambda _{Ridge}$which is the determining value in the reduction the coefficients

## LASSO

-   **L**east **A**bsolute **S**hrinkage and **S**election **O**perator

-   Performs variable selection eliminating independent variables by reducing their coefficients to zero

-   If collinearity exists, only one independent variable is kept in the model and the rest are discarded by reducing their coefficients to zero

    -   This can be a problem is data sets with a lot of collinearity

-   Cannot keep more predictors than observations therefore only recommended for data sets where the number of predictors is less than the number of observations ($p<n$)

-   LASSO uses a variable we will call $\lambda _{LASSO}$ to eliminate the coefficients

## Elastic Net Regularization

-   Determined by a sliding scale that exists between ridge and LASSO by selecting an $\alpha$ between 1 and 0

    -   $\alpha=0$ indicates ridge regression and $\alpha=1$ indicates LASSO

-   Can perform variable selection

-   Can work when the number of independent variables is greater than the number of observations in the data set. ($p>n$)

-   Elastic net uses a balance of both the $\lambda _{Ridge}$ and $\lambda _{LASSO}$


## General Process for Regularization Modeling

-   The GLMNET package in R will be used to perform the modeling.
-   More information on the package can be found [here](https://glmnet.stanford.edu/articles/glmnet.html)
-   First an optimal Lambda needs to be found. There are a lot of techniques for this, but GLMNET provides a built in cross-fold validation method. 
-   ![](LASSOPres_files/images/LASSOLambda.png)![](LASSOPres_files/images/LASSOLambda2.png)
-   The alpha parameter controls whether or not it is a Ridge, LASSO, or Elastic Net Implementation.
-   This function returns an entire group of models, not just one. 

## General Process for Regularization Modeling

-   Once optimal Lambda is found, it is passed into a final model using the non-cv glmnet function.
-   ![](LASSOPres_files/images/LASSOFinal.png)
-   This function returns a single model that can be used for predictions, etc.
-   The GLMNET package contains options for fitting penalized models for many other generalized linear models such as Logistic Regression and Poisson Regression. 

## Human Freedom Index (High Dimension Data)

### Data Overview

-   The Human Freedom Index from the openintro R package
-   This data consists of sociological measures of the different types of freedom. The main dataset has 1458 observations with 123 variables
-   For this example, a single year of complete observations will be used, resulting in 93 observations across 99 variables.
-   Mimics the situation if a researcher attempted to analyze the most recent year of data in isolation.
-   Each column being examined in this data set is a continuous numerical variable.
-   Some variables have high degrees of collinearity because of their relation to one another. For example, total disappearances is expected to have high collinearity with total violent disappearances.

## Human Freedom Index (High Dimension Data)

### Modeling Method

-   pf_ss_homicide (homicide rate) will be the response variable.
-   The remaining 98 variables will be the predictors (excluding any indexes or total scores).
-   The data will be randomly split 80/20 into testing and training sets. 
-   The training sets will be further validated using the GLMNET cross-fold validation functions. 


### What the Data Looks Like

```{r echo = FALSE, message=FALSE, warning=FALSE, results='hide'}
library(ISLR)
library(tidyverse)
library(haven)
library(dplyr)
library(ggpubr)
library(table1)
library(fastDummies)
library(ggplot2)
library(lars)
library(glmnet)
library(data.table)
library(caTools)
library(olsrr)
library(openintro)
library(mice)
library(misty)
eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))
    
  # Model performance metrics
data.frame(
  RMSE = RMSE,
  Rsquare = R_square
)
  
}
```

```{r}
#Human Freedom Index Linear Model
freedomData <- hfi
freedomData <- freedomData %>% filter(year==2016)%>% select(c(-"year",-"ISO_code",-"countries",-"region",-"ef_score",-"ef_rank",-"hf_rank",-"hf_quartile",-"pf_score",-"pf_rank",-"pf_religion_estop_establish",-"pf_religion_estop_operate",-"pf_identity_legal",-"pf_rol_procedural",-"pf_rol_civil",-"pf_rol_criminal",-"pf_ss_women_inheritance_widows",-"pf_ss_women_inheritance_daughters",-"pf_association_political_establish",-"pf_association_political_operate",-"pf_association_sport_operate",-"pf_association_sport_establish",-"pf_identity_divorce",-"pf_association_prof_operate",-"pf_association_prof_establish"))%>%mutate(id = row_number())
#check missing data values
freedomData <- na.omit(freedomData) 
head(freedomData,2)
train <- freedomData %>% sample_frac(.8)
test <- anti_join(freedomData, train, by='id')
ytrain <- train$pf_ss_homicide
ytest <- test$pf_ss_homicide
xtrainLin <- train %>% select(c(-"id"))
xtrain <- train %>% select(c(-"pf_ss_homicide",-"id"))
xtestLin <- test %>% select(c(-"id"))
xtest <- test %>% select(c(-"pf_ss_homicide",-"id"))
xtestFrame <- xtest
xtest <- data.matrix(xtest)
predictors <- data.matrix(xtrain)
resp <- ytrain
linModel <- lm(pf_ss_homicide~., data=xtrainLin)
```

## Human Freedom Index (High Dimension Data)

### What Happens in a Traditional Linear Model?

```{r}
summary(linModel)
```

![Model Output](LASSOPres_files/images/HFIModel1.png){fig-align="center"} ![Model Output](LASSOPres_files/images/HFModel2.png){fig-align="center"}

The model does not work because there aren't enough degrees of freedom.

## Human Freedom Index (High Dimension Data)

### Regularization Method

Each method will have a model fit. These will then have their RSquare and RMSE scores displayed to show a relative performance for each method. In the GLMNET package, alpha controls the method used. An alpha value of 1 corresponds to LASSO regression, a value of 0 corresponds to Ridge Regression, and a value in between corresponds to a form of Elastic Net Regularization.

### Basic Code Structure

-   Perform Cross Validation to acquire the optimal lambda. The alpha term is altered based on the method.
-   Pass the optimal lambda into a new model based on the training data.
-   Examine the impact on the coefficients.
-   Using the model, make predictions on the training data and the test data.
-   Store results and display scores for each method.

## Human Freedom Index (High Dimension Data)

### Fitting LASSO

![Code 1](LASSOPres_files/images/code1.png){fig-align="center"} ![Code 2](LASSOPres_files/images/code2.png){fig-align="center"}

```{r}
set.seed(250)
#LASSO
modelResults <- data.frame(matrix(ncol=6,nrow=0))
colnames(modelResults)<-c("Model","Train_RSquare","Train_RMSE","Test_RSquare","Test_RMSE","CoefficientCount")
model <- cv.glmnet(predictors, resp, alpha=1)
bestLambda <- model$lambda.min
#Optimal Lambda has been fit.
plot(model)
finalModel <- glmnet(predictors,resp, alpha=1, lambda=bestLambda)
coefTable <- coefficients(finalModel)
coefList <- data.frame(matrix(ncol=2,nrow=0))
colnames(coefList)<-c("Predictor","Coefficient")
for(x in 1:nrow(coefTable)){
 if(coefTable[x,1] != 0)
 {rows <- nrow(coefList)
 predNames <- data.frame(coefTable@Dimnames)
   newRow <- c(predNames[x,1],coefTable[x,1])
    coefList[rows+1,] <- newRow    
   } 
}
finalModelPredict <- predict(finalModel, s= bestLambda, newx = predictors)
finalModelTest <- predict(finalModel, s= bestLambda, newx = xtest)
rows<-nrow(modelResults)
newRow <- c("LASSO",eval_results(resp,finalModelPredict,freedomData)$Rsquare,eval_results(resp,finalModelPredict,freedomData)$RMSE,eval_results(ytest,finalModelTest,freedomData)$Rsquare,eval_results(ytest,finalModelTest,freedomData)$RMSE, count(coefList))
modelResults[rows+1,]<-newRow
LASSOCoef <- coefList
model <- cv.glmnet(predictors, resp, alpha=0)
bestLambda <- model$lambda.min
#Optimal Lambda has been fit.
finalModel <- glmnet(predictors,resp, alpha=0, lambda=bestLambda)
coefTable <- coefficients(finalModel)
coefList <- data.frame(matrix(ncol=2,nrow=0))
colnames(coefList)<-c("Predictor","Coefficient")
for(x in 1:nrow(coefTable)){
 if(coefTable[x,1] != 0)
 {rows <- nrow(coefList)
 predNames <- data.frame(coefTable@Dimnames)
   newRow <- c(predNames[x,1],coefTable[x,1])
    coefList[rows+1,] <- newRow    
   } 
}
finalModelPredict <- predict(finalModel, s= bestLambda, newx = predictors)
finalModelTest <- predict(finalModel, s= bestLambda, newx = xtest)
rows<-nrow(modelResults)
newRow <- c("Ridge",eval_results(resp,finalModelPredict,freedomData)$Rsquare,eval_results(resp,finalModelPredict,freedomData)$RMSE,eval_results(ytest,finalModelTest,freedomData)$Rsquare,eval_results(ytest,finalModelTest,freedomData)$RMSE, count(coefList))
modelResults[rows+1,]<-newRow
model <- cv.glmnet(predictors, resp, alpha=.25)
bestLambda <- model$lambda.min
#Optimal Lambda has been fit.
finalModel <- glmnet(predictors,resp, alpha=.25, lambda=bestLambda)
coefTable <- coefficients(finalModel)
coefList <- data.frame(matrix(ncol=2,nrow=0))
colnames(coefList)<-c("Predictor","Coefficient")
for(x in 1:nrow(coefTable)){
 if(coefTable[x,1] != 0)
 {rows <- nrow(coefList)
 predNames <- data.frame(coefTable@Dimnames)
   newRow <- c(predNames[x,1],coefTable[x,1])
    coefList[rows+1,] <- newRow    
   } 
}
finalModelPredict <- predict(finalModel, s= bestLambda, newx = predictors)
finalModelTest <- predict(finalModel, s= bestLambda, newx = xtest)
rows<-nrow(modelResults)
newRow <- c("ENet.25",eval_results(resp,finalModelPredict,freedomData)$Rsquare,eval_results(resp,finalModelPredict,freedomData)$RMSE,eval_results(ytest,finalModelTest,freedomData)$Rsquare,eval_results(ytest,finalModelTest,freedomData)$RMSE, count(coefList))
modelResults[rows+1,]<-newRow
#Elastic Net 2
model <- cv.glmnet(predictors, resp, alpha=.5)
bestLambda <- model$lambda.min
#Optimal Lambda has been fit.
finalModel <- glmnet(predictors,resp, alpha=.5, lambda=bestLambda)
coefTable <- coefficients(finalModel)
coefList <- data.frame(matrix(ncol=2,nrow=0))
colnames(coefList)<-c("Predictor","Coefficient")
for(x in 1:nrow(coefTable)){
 if(coefTable[x,1] != 0)
 {rows <- nrow(coefList)
 predNames <- data.frame(coefTable@Dimnames)
   newRow <- c(predNames[x,1],coefTable[x,1])
    coefList[rows+1,] <- newRow    
   } 
}
finalModelPredict <- predict(finalModel, s= bestLambda, newx = predictors)
finalModelTest <- predict(finalModel, s= bestLambda, newx = xtest)
rows<-nrow(modelResults)
newRow <- c("ENet.50",eval_results(resp,finalModelPredict,freedomData)$Rsquare,eval_results(resp,finalModelPredict,freedomData)$RMSE,eval_results(ytest,finalModelTest,freedomData)$Rsquare,eval_results(ytest,finalModelTest,freedomData)$RMSE, count(coefList))
modelResults[rows+1,]<-newRow
#Elastic Net 3
model <- cv.glmnet(predictors, resp, alpha=.75)
bestLambda <- model$lambda.min
#Optimal Lambda has been fit.
finalModel <- glmnet(predictors,resp, alpha=.75, lambda=bestLambda)
coefTable <- coefficients(finalModel)
coefList <- data.frame(matrix(ncol=2,nrow=0))
colnames(coefList)<-c("Predictor","Coefficient")
for(x in 1:nrow(coefTable)){
 if(coefTable[x,1] != 0)
 {rows <- nrow(coefList)
 predNames <- data.frame(coefTable@Dimnames)
   newRow <- c(predNames[x,1],coefTable[x,1])
    coefList[rows+1,] <- newRow    
   } 
}
finalModelPredict <- predict(finalModel, s= bestLambda, newx = predictors)
finalModelTest <- predict(finalModel, s= bestLambda, newx = xtest)
rows<-nrow(modelResults)
newRow <- c("ENet.75",eval_results(resp,finalModelPredict,freedomData)$Rsquare,eval_results(resp,finalModelPredict,freedomData)$RMSE,eval_results(ytest,finalModelTest,freedomData)$Rsquare,eval_results(ytest,finalModelTest,freedomData)$RMSE, count(coefList))
modelResults[rows+1,]<-newRow
```

The best Lambda chosen by this model was `r round(bestLambda,4)`

## Human Freedom Index (High Dimension Data)

### Results

After repeating the process for Ridge, and 3 forms of Elastic Net, the end result of the modeling gives this table:

```{r}
print(modelResults)
print(LASSOCoef)
```

### Notes

-   Pure LASSO had the best fit.
-   The model is still potentially overfit. (10 predictors vs 92 observations)
-   Now there are features available for a more refined linear model.
-   "Grouped" variables still need to be adjusted for.

## Jackson Heart Study (JHS) Data

JHS Visit 1 dataset of 2653 observations and 198 variables

For this example, we'll model the Total Depressive Symptoms Score (depression) as the Dependent variable (y).

```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
#Code based on tutorial from David Caughlin's LASSO Regression in R
#https://youtu.be/5GZ5BHOugBQ
#Import libraries 
library(GGally)
library(haven)
library(plyr)
library(dbplyr)
library(dtplyr)
library(tidyverse)
library(readr)
library(caret)
library(randomForest)
library(mice)
library(gdata)
library(ggplot2)
library(glmnet)
library(olsrr)
library(genridge)
library(car)
library(dplyr)
library(repr)
library(ggcorrplot)
library(plotly)
library(reshape2)
library(AER)
library(mctest)
library(qgraph)
library(fmsb)
library(coefplot)
```

```{r include=FALSE}
#Import data sets
analysis1 <- read_dta("analysis1.dta")
V1_Impute <- read_dta("data_imp2.dta")
```

```{r include=FALSE}
#Regression Model for ALL continuous variables
BIG_Mod <- lm(depression ~ ., data=V1_Impute)
summary (BIG_Mod)
```

```{r}
#New dataset from initial lm model
 
#Take out non-numeric, categorical, and singularities, keep Y/N from LM model
LM_Data <- V1_Impute %>% dplyr::select(depression,fasthours,age,alc,bmi, weight,neck,betablkmeds,diureticmeds,dmmedtype, fastinginsulin, homa_ir,aldosterone, adiponectin,maneuvers, asthma,fev1,fev6,fev1pp,systlvdia,lvmecho,repolarant,repolarantlat,minorscarantlat,miecg,visionlossever,hsgrad,    dailydiscr,lifetimediscrm,discrmburden,perceivedstress,weeklystress,vitamind2,vitamind3,darkgrnveg,nbpctresiden1mi,sportindex,hyindex)
```

```{r}
LM_Mod <-lm(depression ~., data=LM_Data)
summary(LM_Mod)
```

## JHS: Residuals

```{r}
#get list of residuals 
res <- resid(LM_Mod)
#produce residual vs. fitted plot
plot(fitted(LM_Mod), res)
#add a horizontal line at 0 
abline(0,0)
```

## JHS: Heavy Tails/Nonparametric

```{r}
#create Q-Q plot for residuals
qqnorm(res)
#add a straight diagonal line to the plot
qqline(res) 
```

## **Correlation Matrix heat map:high multicollinearity for JHS**

-   2 or more predictor variables strongly linearly dependent
-   leads to overfitting and low prediction accuracy

```{r}
CorMatrix1_lm <- ggcorr(LM_Data, label_alpha = FALSE)
CorMatrix1_lm
```

## **JHS Variance Inflation Factor (VIF) Scores : Multicollinearity**

```{r}
#Regression Model for smaller LM dataset (Multicollinear)
VIF <- vif(LM_Mod)
Tolerance = 1/VIF
v1 <- data.frame(VIF)
write.table(v1, "VIF Table")
v2 <- data.frame(Tolerance)
write.table(v2, "VIF Table")
v.table = data.frame(cbind(v1,v2))
print(v.table)
```

## JHS: Highly Multicollinear

-   can use regularization to alleviate

    ![](LASSOPres_files/images/CorrPlot1.png)

## Why LASSO or Ridge for JHS?

Modifying Regression Models with Regularization:Choosing the Penalty Term/Optimal Lambda

![](LASSOPres_files/images/L1L2Constrain.png)

^~James et al., 2013~^

## Jackson Heart: LASSO (𝞪=1), L1 Norm

**𝞴 x \|Slope\|**

```{r}
#define response variable
y <- LM_Data$depression
#define matrix of predictor variables
x <- data.matrix(LM_Data[, c('fasthours','age','alc','weight','neck','bmi','betablkmeds','diureticmeds', 'dmmedtype','fastinginsulin', 'homa_ir','aldosterone','adiponectin','maneuvers','asthma','fev1','fev6','fev1pp','systlvdia','lvmecho','repolarant','repolarantlat','minorscarantlat','miecg','visionlossever','hsgrad','dailydiscr','lifetimediscrm','discrmburden','perceivedstress','weeklystress','vitamind2','vitamind3','darkgrnveg','nbpctresiden1mi','sportindex','hyindex')])
LASSO_fit <- glmnet(x,y,alpha = 1)
plot(LASSO_fit)
```

## Jackson Heart: LASSO (𝞪=1), L1 Norm

```{r}
#cross-validated fit of lambda
LASSO_cvfit <- cv.glmnet(x, y, alpha=1)
plot(LASSO_cvfit)
LASSO_cvfit$lambda.min
```

## Jackson Heart: LASSO (𝞪=1), L1 Norm

More Variables dropped as Lambda is increased. Higest VIF's: BMI, weight, fev1, fev6

```{r}
#LASSO regression model coefficients/parameter estimates
coef(LASSO_fit,s=c(0.002,0.04,0.2,2.0))
```

```{r}
```

## Jackson Heart: Ridge (𝞪=0), L2 Norm

**𝞴 x Slope^2^**

```{r}
Ridge_fit <- glmnet(x,y,alpha = 0)
plot(Ridge_fit)
```

## Jackson Heart: Ridge (𝞪=0), L2 Norm

```{r}
#cross-validated fit of lambda
Ridge_cvfit <- cv.glmnet(x, y, alpha=0)
plot(Ridge_cvfit )
Ridge_cvfit$lambda.min
```

## Jackson Heart: Ridge (𝞪=0), L2 Norm

```{r}
#Ridge regression model coefficients/parameter estimates
coef(Ridge_fit,s=c(0.03,0.34,3.0,30))
```

```{r include=FALSE}
#Partitioning Data 80/20 Split
set.seed(123)
#Create Index Matrix: 80% split matrix NOT list only split once
index <- createDataPartition(LM_Data$depression, p=0.8, list=FALSE, times=1)
#Create Test and Training df
#-is all except index
train_df <- LM_Data[index,]
test_df <- LM_Data[-index,]
```

```{r include=FALSE}
# k-fold Cross Validation to train LASSO
#(because sample size is large, using 10-fold)
#Train Control Function from Caret Package
#Create Object to assign all the training method info to 
#cross validation method, 10 fold
tctrl_method <- trainControl(method='cv', number=10,
                           savePredictions = 'all')
#Specify & train LASSO Regression Model
#Create vector of Lambda Values to find optimal (LASSO Tuning Parameter)
lambda_vector <- 10^seq(5,-5, length=500)
set.seed(123)
#LASSO Regression Model estimated from Training data and 10-fold cv
# dot is all other variables except outcome variable
#grand mean center, "center" and standardize, "scale" at this step
#c=combine, glmnet in caret package, alpha=1 for lasso (0 for ridge)
```

```{r include=FALSE}
#LASSO Model (alpha=1)
LASSO_mod1 <- train(depression ~ .,
              data=train_df,
              preProcess=c("center", "scale"),
              method="glmnet",
              tuneGrid=expand.grid(alpha=1,lambda=lambda_vector),
              trControl=tctrl_method,
              na.action=na.omit
              )
#Warning Message OK!!
```

```{r include=FALSE}
#Best Optimal Lambda
LASSO_mod1$bestTune
LASSO_mod1$bestTune$lambda
#plot log(lambda) & RMSE 
plot(log(LASSO_mod1$results$lambda),
     LASSO_mod1$results$RMSE,
     xlab="log(lambda)",
     ylab="RMSE",
     xlim=c(-6,3))
#print(log(0.013373))#check with log(lambda)
```

```{r include=FALSE}
#Model Prediction on test data
predict1 <- predict(LASSO_mod1, newdata=test_df)
#Model Accuracy
LASSO_mod1_rmse <- data.frame(RMSE=RMSE(predict1, test_df$depression))
#RMSE 10
#R^2E
LASSO_rss <- sum((predict1 - test_df$depression) ^ 2)
LASSO_tss <- sum((test_df$depression - mean(test_df$depression)) ^ 2)
LASSO_mod1_rsq <- 1 - LASSO_rss/LASSO_tss
LASSO_mod1_rmse
LASSO_mod1_rsq
```

```{r include=FALSE}
#Compare LASSO to Ridge Regression
#Set Seed (reproducible results)
set.seed(123)
#Ridge Model (alpha=0)
Ridge_mod2 <- train(depression ~ .,
              data=train_df,
              preProcess=c("center", "scale"),
              method="glmnet",
              tuneGrid=expand.grid(alpha=0,lambda=lambda_vector),
              trControl=tctrl_method,
              na.action=na.omit)
#Warning Message OK!!
```

```{r include=FALSE}
#Model Prediction on test data
predict2 <- predict(Ridge_mod2, newdata=test_df)
#Model Accuracy
Ridge_mod2_rmse <- data.frame(RMSE=RMSE(predict2, test_df$depression))
#RMSE 10
#R^2E
Ridge_rss2 <- sum((predict2 - test_df$depression) ^ 2)
Ridge_tss2 <- sum((test_df$depression - mean(test_df$depression)) ^ 2)
Ridge_mod2_rsq <- 1 - Ridge_rss2/Ridge_tss2
Ridge_mod2_rmse
Ridge_mod2_rsq
```

```{r include=FALSE}
#ElasticNet Regresstion
#tctrl_method (using from LASSO earlier)
#Set Seed (reproducible results)
set.seed(123)
#Specify OLS model estimated with training data, train_df
#10-fold cross validation
EN_mod3 <- train(depression ~ .,
              data=train_df,
              preProcess=c("center", "scale"),
              method="glmnet",
              tuneGrid=expand.grid(alpha=0.5,lambda=lambda_vector),
              trControl=tctrl_method,
              na.action=na.omit)
```

```{r include=FALSE}
#Predict outcome from training data based on test data using ElasticNet
predict3 <- predict(EN_mod3, newdata=test_df)
#Assess model performance
#Model Accuracy
EN_mod3_rmse <- data.frame(RMSE=RMSE(predict3, test_df$depression))
#RMSE 10
#R^2E
EN_rss3 <- sum((predict3 - test_df$depression) ^ 2)
EN_tss3 <- sum((test_df$depression - mean(test_df$depression)) ^ 2)
EN_mod3_rsq <- 1 - EN_rss3/EN_tss3
EN_mod3_rmse
EN_mod3_rsq
```

```{r}
#Compare LASSO to OLS Regresstion
#tctrl_method (using from LASSO earlier)
#Set Seed (reproducible results)
set.seed(123)
#Specify OLS model estimated with training data, train_df
#10-fold cross validation
OLS_mod4 <- train(depression ~ .,
             data=train_df,
             preProcess=c("center","scale"),#grand means center and scale to make results comparable to LASSO
             method="lm",
             trControl=tctrl_method,
             na.action=na.omit)
#print(mod4)
```

```{r include=FALSE}
#Predict outcome from training data based on test data using OLS
predict4 <- predict(OLS_mod4, newdata=test_df)
#Assess model performance
#Model Accuracy
OLS_mod4_rmse <- data.frame(RMSE=RMSE(predict4, test_df$depression))
#RMSE 10
#R^2E
OLS_rss4 <- sum((predict4 - test_df$depression) ^ 2)
OLS_tss4 <- sum((test_df$depression - mean(test_df$depression)) ^ 2)
OLS_mod4_rsq <- 1 - OLS_rss4/OLS_tss4
OLS_mod4_rmse
OLS_mod4_rsq
```

## Jackson Heart: Comparing Models

![](LASSOPres_files/images/Comp_Table.png)

```{r include=FALSE}
#compare models 
compare_models(LASSO_mod1,Ridge_mod2, metric="RMSE")
compare_models(LASSO_mod1,Ridge_mod2, metric="Rsquared")
compare_models(LASSO_mod1,EN_mod3, metric="RMSE")
compare_models(LASSO_mod1,EN_mod3, metric="Rsquared")
compare_models(LASSO_mod1,OLS_mod4, metric="RMSE")
compare_models(LASSO_mod1,OLS_mod4, metric="Rsquared")
compare_models(Ridge_mod2,EN_mod3, metric="RMSE")
compare_models(Ridge_mod2,EN_mod3, metric="Rsquared")
compare_models(Ridge_mod2,OLS_mod4, metric="RMSE")
compare_models(Ridge_mod2,OLS_mod4, metric="Rsquared")
compare_models(EN_mod3,OLS_mod4, metric="RMSE")
compare_models(EN_mod3,OLS_mod4, metric="Rsquared")
```

## Jackson Heart: Comparing Models

```{r}
#Compare LASSO and OLS predictive performance based on test_df
comp <- matrix(c(LASSO_mod1_rmse, LASSO_mod1_rsq,
                 Ridge_mod2_rmse,Ridge_mod2_rsq,
                 EN_mod3_rmse,EN_mod3_rsq,
                 OLS_mod4_rmse,OLS_mod4_rsq),
               ncol=2,byrow=TRUE)
#Labels
colnames(comp) <- c("RMSE","R-squared")
rownames(comp) <- c("LASSO", "Ridge", "ElasticNet", "OLS")
print(comp)
```


## Summary and Conclusion